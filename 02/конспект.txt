одинична фнкція активації в нулі переходить в одиничку буква z обернена hardlim
лінійна purelin бісектриса
лоігістична функція S log

Одношарова мережа складається з одного прошарку, де кожен вхід з'єднаний з усіма 
нейронами прошарку за допомогою матриці ваг. Кожен нейрон в цьому прошарку обчислює 
скалярний вихід, який потім збирається разом у вектор виходу за допомогою функції активації.

У багатошаровій мережі є кілька прошарків. Кожен прошарок має свою власну матрицю ваг,
 вектор зміщення та вектор виходу. Вагові матриці, з'єднані з входами прошарку, називаються
 вагами входу, а з виходами - вагами виходу. Кожен прошарок може мати свою функцію активації.

Різниця між ними полягає в складності обчислень та можливостях. Одношарові мережі можуть
 вирішувати прості завдання, тоді як багатошарові мережі мають потужніші можливості,
 оскільки вони можуть навчатися нелінійним зв'язкам між входами та виходами. 

Мережі із прямою передачею сигналу Ця мережа, яка не має зворотних зв'язків, називається мережею із прямою передачею сигналу.Такі мережі
часто мають один або більше прихованих прошарків нейронів із сигмоїдальними функціями активації, у той
час як вихідний прошарок містить нейрони з лінійними функціями активації.

Моделювання мережу створена мережа діє на вхідні дані

Статичні мережі не має зворотніх звязків і затримок все перебуває в спокої
зазвичай створюють лінійну нейронну мережу
P = [-1 0 0 1; 0 -1 1 -1];
Тепер можна моделювати мережу:
A = sim(net,P) % Моделювання мережі net із вектором входу P та виходом A
A = -1 -2 2 -1
Результат слід інтерпретувати так. На вхід мережі подається послідовність чотирьох вхідних сигналів, і
мережа генерує вектор виходу з чотирьох елементів. Результат був би той самий, якби було 4 однакових
мережі, що функціонують паралельно, і на кожну мережу був би поданий один із векторів входу та
генерувався один із виходів.

Динамічні мережі містять лінії затримки або зворотні звязки або і то і то
не використовують груповий спосіб подачі вхідного сигналу нічого не змінює
є послідовний(P = {-1 -1/2 1/2 1};) груповий(P = [-1 -1/2 1/2 1];)
та змішаний свосіб подачі вхідного сигналі(P = {[–1 1] [–1/2 1/2] [1/2 –1/2] [1 –1]};)
змішаний це груповий + полсідовний
Змішані є сенс використовувати у динамічних мережах бо затримки дасть матриці суть шо ми беремо перший перед ним нічого тому нулі і по черзі

Навчання adapt(зміна ваг після подачі кожного послідовного прикладу може працювати тільки в персептроні)
 і train(ваги скореговуються як подадуться всі навчальні приклади) навчання
властивістю узагальненя має володіти нейронна мережа тобто має видавати бажаний результат не тільки на тих прикладах шо навчалася але й на інших прикладах

Лінійні нейронні мережі, що обговорюються в цьому розділі, за своєю структурою аналогічні
персептрону і відрізняються лише функцією активації, яка є лінійною. Вихід лінійної мережі може приймати
будь-яке значення, у той час як вихід персептрону обмежений значеннями 0 або 1.
Лінійна нейронна мережа це мережа прямого поширення

команди sim gen sim train adapt синтаксис нейронних мереж